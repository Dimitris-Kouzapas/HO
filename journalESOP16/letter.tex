%\title{Example letter using the newlfm LaTeX package}
%
% See http://texblog.org/2013/11/11/latexs-alternative-letter-class-newlfm/
% and http://www.ctan.org/tex-archive/macros/latex/contrib/newlfm
% for more information.
%
%\documentclass[12pt,stdletter,orderfromtodate,sigleft]{newlfm}
\documentclass[11pt,a4paper]{article}
\usepackage{blindtext, xfrac,xcolor,geometry}

\newcommand{\answ}[1]{\smallskip \emph{\textcolor{blue}{\textbf{Answer}:  #1}}}

\newcommand{\tbd}{\smallskip \textbf{\textcolor{red}{TO DO!}}}
%\newcommand{\checkthis}{\smallskip \textbf{\textcolor{magenta}{CHECK!}}}
\newcommand{\checkthis}{}
 
%\newlfmP{dateskipbefore=50pt}
%\newlfmP{sigsize=50pt}
%\newlfmP{sigskipbefore=50pt}
% 
%\newlfmP{Headlinewd=0pt,Footlinewd=0pt}
% 

\begin{document}
 
 \title{Answers to the Reviewers}
 \author{D.\,Kouzapas \and J.A.\,P\'{e}rez \and N.\,Yoshida}
 \maketitle

\noindent
Many thanks to both reviewers for their effort in producing very detailed comments and suggestions on our paper.
We have made an effort to address all of them; in passing, we have revised and improved several parts of the paper.
 
\section{Answers to Reviewer 1 (1 comment)}


\begin{enumerate}
    \item  In the previously published encodings of untyped higher-order process calculi, are there any that do not preserve session type disciplines? 
    
    If so, it would be interesting to see what they are and, if not (or if the authors are not aware of any), it would be worth pointing this out explicitly. 
    
    No matter what, this would improve oneâ€™s understanding of the type-preserving property of encodings.
    
    \answ{To our knowledge, we are the first to study the expressiveness of higher-order process calculi from the perspective of typability based on session types. We are not aware of other encodings not preserved by typing.}
\end{enumerate}



\section{Answers to Reviewer 2 (41 comments) }

\begin{enumerate}
\item Please correct the spacing within your macros; in particular for the macro
  that defines the brackets of encodings and the relations in types. The
  brackets $[|$ and $|]$ are often reduced to $[$ and $]$ in the PDF and the distance of
  the little diamond at the end of the operator for relations in types varies
  very much. However, since the paper does not use similar notations, none of
  these things produce any real ambiguities.
  
  \answ{We have revised the macros for translations and encodings.}
  
\item Please check for overfull horizontal boxes. There are several clearly visible
  such overfull boxes (e.g. at the bottom of Page 31).
  
  \answ{We have revised this.}
  
\item Page 5: 'We sometimes write $*P$ to denoted' should be 'We sometimes write $*P$ to
  denote'.
  
  \answ{Fixed.}
  
\item  Page 6: What are 'free ion variables'? Is this a spelling mistake?

\answ{Yes, this was a typo, now fixed.}

\item Page 7: Can you provide some intuition on the definition of the isomorphism
  between types. Is it correct that isomorphic types can only differ in
  recursion, where both types need to loop in the same way but not necessarily
  always put the recursion variable at the same place? Or is the difference
  between isomorphic types larger than that?
  
  \answ{Yes, indeed this is a good intuitive description of type equivalence (Definition 3.1): it  equates (recursive) types which describe the same protocol but may differ in their unfoldings.}
  
\item  Page 9: Can you explain shortly when to use Send (Rcv) and when Rec (Acc).

\answ{Send and Recv type prefixes on linear names, whereas Rec and Acc type prefixes on shared names.}

\item  Page 11: What is the `$t$' that is used in Figure 6? Where does it comes from?
  What is it used for? Is it a special, i.e., reserved name, for this
  translation? If so, then please explain the nature and purpose of $t$ in the
  text and add the necessary freshness conditions for $t$ in Figure 6.
  
  \answ{Name $t$ is a fresh name. Characteristic processes contain an output on $t$ which is meant to match a corresponding input in the trigger process. We have added the freshness condition in Figure 6. } \checkthis
  
\item Page 11: Note that you explain the refined LTSs ONLY in the appendix. From the
  paper itself it is absolutely not clear and a little confusing that you use
  different kinds of arrows (variants of $->$ versus $|->$). Please explain this or
  unify the arrows that are used in the paper (before the appendix). Please also
  explain why you introduce this new step relation.
  
  \answ{We completely understand the reviewer's confusion. We have reworked Section 3.3.2 to clarify the different notions and notations, which are fully explained in the appendix. We have also added the whole set of typing rules in the main text, for the sake of completeness.} \checkthis
  
\item Page 11: What does it means to 'inhabit a type'?

\answ{A process $P$ is said to inhabit a type $T$ if $P$ has type $T$.}

\item  Page 11: Do you not need to require that $x$ is fresh in $V$ in the Definition (1)
  at the bottom of Page 11?
  
  \answ{Yes, this freshness assumption was implicit. We have now explicitly stated Barendregt's convention to make this clear - see Page~6.}
  
\item  Page 16: You indicate that the typing rules for parallel composition (in
  combination with the other criteria) ensure that precise encodings translate
  the parallel operator homomorphically. Can you explain this.
  
  \answ{What we mean here is that since the typing of $P_1 \parallel P_2$ is compositional (it follows directly from the individual typings for $P_1$ and $P_2$), the criterion of homomorphism wrt parallel is naturally satisfied.}
  
\item  Page 16: I see your motivation for type preservation and type soundness. Still
  these criteria are quite strict. Did you think about weaker (variants of
  these) criteria?
  
  \answ{It is true that these criteria are strict, but this is because we focus on encodability results based on ``high-quality'' translations, and rule out the rest. In this work, we did not need weaker criteria for encodability results.}
  
\item  Page 16: In Definition 4.5. Case 3(a)(ii) it should be $[|P'|] $ instead of $P'$
  and $Q$ instead of $[|Q|]$.
  
  \answ{Yes, this was a typo, now fixed.}
  
\item  Page 16: Your definition of operational soundness is not correct. It basically
  states that every SEQUENCE of target term steps is the translation of a single
  source term step. This is not what you are intending to require or prove later
  in the paper. 
  What you show later is what Gorla called weak soundness:
  If $[|P|] |-> Q$ then there are $P'$ and $Q'$ such that $P |-> P'$ (actually Gorla is
  more relaxed here and requires only $P |=> P'$) and $Q |=> Q'$ and the terms
  $[|P'|]$ and $Q'$ are related.
  Not that in weak soundness you require that for all steps $[|P|] |-> Q$ there
  is some $Q |=> Q'$, whereas in your formulation you require the property for all
  sequences $[|P|] |=> Q$.
  
  \answ{The reviewer is right, and we have adjusted the definition of soundness to reflect that $Q$ may need to perform some steps in order to be related to $[[P']]$. We only wish to remark that this flexibility is required in some, but not all, of our results. Indeed, there are cases in which $Q$ and $[[P']]$ are  related.} \checkthis
  
\item  Page 17: As explained by Gorla in the paper `A taxonomy of process calculi for
  distribution and mobility.' the composition of two operational corresponding
  encodings is not necessarily operational corresponding again. So encodings are
  not composable in general. He then shows that encodings that satisfy full
  abstraction and are reduction closed are composable. You already require full
  abstraction and all equivalences that you use are reduction closed. So one way
  to fix this problem would be to add reduction closedness to Proposition 4.1.
  
  \answ{The reviewer is right, and we have made the assumption on reduction closedness (and a reference to Gorla's result) explicit. We would like to remark that composability only relies on ``half'' of full abstraction (the left to right direction).} \checkthis
  
\item  Page 17: Definition 4.7.2 contains again a wrong variant of operational
  soundness. Again you need a typed and now also labelled variant of weak
  soundness as used by Gorla.
  
  \answ{Yes, we have adjusted this.}

\item  Page 18: In Definition 5.1 the second case introduces the name $x$. Why $x$? What
  is the purpose of this name? As I understand it, this is used in the encoding
  function later and indeed NEEDS to be a special reserved name $x$. If so, please
  clarify that $x$ is special reserved name that you use in the encoding function.
  
  \answ{We have addressed this by specifying that $x$ is a fresh, i.e., not occurring anywhere else. We also explicitly define what we mean by ``fresh'' (at the beginning of the paper).}
  
\item Page 19: I think that you NEED to require in Figure 8 that $x$ does not occur in
  $\sigma$ for the translation of output, input, and $\lambda$ abstractions and that
  $n$ does not occur in $\sigma$ for the translation of restriction. 
  
  Moreover, in
  the translation of the output and the translation of $\lambda$ abstraction I
  would have expected that you need to add $x$ to $\sigma$ on the right side. Else,
  some $x$ in $Q$ might be wrongly translated to $x_x$, e.g. in when translating the
  term $\lambda x. y x$.
  
  \answ{The reviewer is right. Concerning the first part of the comment: conditions on bound names are not needed now, given Barendregt's convention. Concerning the second part: we have modified Figure 8 to make sure that bound variables (such as $x$ in $\lambda x. y x$) are included in $\sigma$ and so do not get wrongly translated.} \checkthis
  
\item  Page 20: The encoding function introduces several names for binders. I think
  it is essential here, that these names (as e.g. $z$ and $x$ in the first case) do
  not already occur in the term. 
  As described by Gorla, you can implement such
  special reserved names by a renaming policy without violating the criteria of
  a precise encoding. Since using a renaming policy might add confusion to the
  encoding function, I suggest that instead you just add the necessary freshness
  conditions and mention somewhere in the text that such fresh names can be
  implemented by a renaming policy. I regard, however, the freshness conditions
  as important here. 
  
   \answ{We understand freshness conditions are important here, but they are redundant/unnecessary due to Barendregt's convention: this way, e.g., in the first line (output), variables $z$ and $x$ are bound and so different from any other objects, and in particular different from $w$. An analogous argument applies for $y$ and $s$ in the second line (input) and for $X$ and $z_X$ in the case of recursion.}
  
  Please correct me if I am wrong. I think that in the first
  case (output of a name) you need to require that $x$ and $z$ are different from $w$.
  In the second case (input of a name) you need that $y$ is different from $s$ and
  does not occur in $Q$. In the second but last case (recursion) you need that $X$
  is not already in $f$ and, I think, also that $y$ is different from $z_X$ and $s$.
  
  Moreover, if I compare this encoding function for the last two cases of
  recursion and recursion variables with the example presented later, I had the
  impression that you need to use $||\tilde{n}||$ instead of $\tilde{n}$ in the
  encoding of recursion and to use $\tilde{n}$ instead of $||\tilde{n}||$ in the
  encoding of recursion variables. Can you please check this once more.
  
  \answ{Both encodings are correct. The encoding of $\mu X. P$ is correct because we use variables $||\tilde{n}||$ in the abstraction, whereas the encoding of $X$ is correct because we use names $\tilde{n}$ in the application. Notice that the encoding of the recursion variable $X$ has been simplified in this revision.}
  \checkthis
  
\item Page 20: I had difficulties in reconstructing the examples of the encoding
  function. I find it very confusing, that you swap the names that you use in
  the encoding function. I understand that you e.g. change the name $s$ in the
  encoding of $P$ at page 20 into $s_1$. But why do you use $z$ instead of $y$ and $x$
  instead of $z_X$ (encoding of recursion)? All three of these renamings can be
  done by alpha conversion, but they are really confusing. There are similar
  swappings of names in the following examples (see below). Could you please
  stick for the examples to the names that you use in Figure 9 or add only an
  index (as you did when changing $s$ into $s_1$)?
  
  \answ{We have revised the example in which we illustrate the encoding of recursion, trying to keep consistency with the notation in the encoding definition.} \checkthis
  
\item  Page 21: In the encoding of $a!\langle m \rangle.X$ the name $x$ should be $z_X$ and the last two
  $z$ should be $y$. Moreover, according to Figure 8 the second occurrence of z
  becomes $x_z$ (that is why you need to add $x$ to $\sigma$ in the definition) and
  the last occurrences of $x_a$, $x_m$ and z would become $x_{x_a}$, $x_{x_m}$, and $x_z$.
  I am not sure how you avoid the renamings into $x_{x_a}$, $x_{x_m}$, and $x_z$ in the
  end.
  
  \answ{Following our previous answer, we have revised the example to maintain consistency with the definition. because of the modification to the auxiliary mapping, we do not have wrong renamings for variables.} \checkthis
  
\item Page 21: Try to avoid page breaks within a single formula as at the bottom of
  Page 21.
  
  \answ{We have moved the corresponding processes in a separate figure.}
  
\item Page 22: Proposition 5.1 claims to prove type preservation, but the proof in
  the appendix is about what you introduced before as type soundness. Type
  preservation follows directly from the definition of the translation of types.
  Type soundness indeed is the more interesting property, so I assume that you
  were intending to show type soundness. The same holds for the Propositions
  5.4, 6.1, and 6.4 and their corresponding proofs in the appendix. You should
  also check the proofs of the Theorems that use these propositions.
  
  \answ{The reviewer is right: we state type preservation but the proof corresponds to type soundness. We have clarified this in all four statements.}
  
\item  Page 22/23: The cases 1.d - f of Proposition 5.2 are not correct. You
  distinguish these cases by a property on structural congruence of $P'$.
  Unfortunately, $P'$ is always structural congruent to the term
  $(\nu \emptyset) (P' | 0\{m/x\})$ as well as to the term
  $(\nu \emptyset) (P' | 0\{\lambda y. Q/x\})$. So the cases 1.d and 1.e are not
  distinguished and the case 1.f will never be applied. 
  
  I suppose that your
  intention is to describe with $P_2\{m/x\}$ and $P_2\{\lambda y. Q/x\}$ the remainder
  of the input that is consumed in the step. I am not sure, whether there is a
  safe way to address the input with structural congruence; but if it works then
  surely only by fixing it in $P$ as well as $P'$. However, I think that Proposition
  5.2 is really hard to read, while at the same time I appreciate that you
  describe so clearly the correspondence between source and target terms. 
  
  If I
  may offer a suggestion that is completely based on my personal opinion: I
  would simplify the formulation of Proposition 5.2 (closer to the formulation
  of operational correspondence as criterion at Page 16) and instead describe
  the different cases in the text. But this is really just a suggestion.
  
  \answ{Thanks for the remark and suggestion. We have revised the formulation of 1(d)--1(f) by fixing $P$ up to structural congruence. \checkthis}
  
\item Page 25: In the first case of the encoding in Figure 10, I think, a should be 
  different from $u$ and $y$ should be fresh in $Q$. In the last two cases of the
  encoding of terms $s$ should be different from $x$ and $u$ and fresh in $P$.
  
  \answ{Here again these conditions are correct, but are unnecessary in the light of Barendregt's convention.}
  
\item  Page 25: In the respective last part of the equations that present the
  encodings of $Client_1$ and $Client_2$ there are two outputs on $s_1$. In both
  examples the respective second output should be on $s_2$.
  
  \answ{We have fixed this.}
  
\item  Page 28: In the encoding of $P_1$ $y$ should be $x$, the first two $x$ should be $y$,
  and $t$ should be $s$. 
  
  In the encoding of $P_2$ $b$ should be a, the brackets around
  $0 | *b?(y).y?(x).[|R|]^2$ are missing, and after the $P$ after the first step
  should be $[|R|]^2$. Moreover, it is more common to write $|=>^{2*(n-1)}$ instead
  of $|=>_{2*(n-1)}$.
  
  \answ{We have fixed all the inaccuracies.}
  
\item  Page 29: In the encoding of $Q_1$ $y$ should be $x$, the first two $x$ should be $y$,
  and $t$ should be $s$. 
  
  In the encoding of $Q_2$, $t$ should be $a$ and the brackets
  around $0 | a?(y).y?(x).[|R|]^2$ are missing. Moreover, please state that $R$ does
  not contain session names.
  
    \answ{We have fixed all the inaccuracies. Notice that $R$ can contain (linear) session names. \checkthis}
  
\item Page 30: In the second line of Page 30 it should be $[|\cdot|]^2$ instead of
  $[|\cdot|]^1$.
  
  \answ{We have fixed this.}
  
\item Page 30: In the presented step of the encoded term the brackets around
  $0 | a?(y).y?(x).[|P|]$ are missing and the two occurrences of P should be
  $[|P|]$.
  
  \answ{We have fixed this.}
  
\item Page 30/31: According to Definition 3.7 you consider only output barbs in this
  paper. So, strictly speaking, neither $n$ nor $m$ are barbs of $P_1$ or $P_2$ in the
  proof of Theorem 5.4. Moreover, (Def. 4.5-2(a)) should be (Def. 4.5-3(a)) and
  Prop. 3.1 is Lemma 3.1. At Page 31 of this proof you use an equivalence that
  you did not introduce before (or that I did not find). Do you mean barbed
  congruence here (the symbol was slightly different)?
  
  \answ{We have adjusted the definition of barb to consider also selection prefixes. The references to prior statements were corrected. Also, the symbol for the behavioral equivalence was fixed.}
  
\item  Page 31: In the proof of Corollary 5.1 (b) the important argument is, I think,
  that both of the presented encodings do not need shared names to encode
  communication on session names. This seems to be the case, but is not obvious
  from the encodings, since they do not distinguish between the nature of names.
  Please add a short explanation to the proof.
  
  \answ{We have added a sentence to the proof.}
  
\item  Page 33: In the Case 2.a) of Proposition 6.2 you use $Q$ (two times) for a
  source term but you already use Q as a target term in Case 2. Do you mean R
  instead of Q in Case 2.a)?
  
  \answ{We have fixed this.}
  
\item  Page 34: In Figure 11 in the second case $z$ should be different from $x$ and
  fresh in $P$. In the third case $s$ should be different from $x$ and fresh in $V$.
  In the last case of encodings of terms $s$ should be different from $x$ and fresh
  in $P$ and $V$.
  
  \answ{Here again these conditions are correct, but are unnecessary in the light of Barendregt's convention.}
  
\item  Page 36: Why do you use unordered sets instead of tuples in Definition 6.4?
  As I understand it, you use $\tau$ for reduction steps in general and $\tau_\beta$
  to describe the specific case of a reduction step that performs a beta
  reduction. If so, don't you need to add the side condition
  ``if $\tau \neq \tau_\beta$'' to the case for $\tau$ in Definition 6.4?
  
  \answ{We didn't use tuples because we would need tuples of different lengths. We have revised the definition so as to have sequences of actions, rather than unordered sets. }
  
\item  Page 36/37: In the Cases 1.a) and 1.b) of Proposition 6.5 you use $n$ for two
  different purposes: as channel name and as the number of labels. Maybe use $k$
  instead for the number of labels as done in the text below.
  In Case 2.a) you use the Label $l$ for the target term step as well as the
  source term step. I think it should be some $l'$ for the source term step and
  that you need to add that $l_1 = l$.
  In Case 2.e) you may require that $l \neq \tau_\beta$ in order to distinguish
  this case from Case 2.d).
  
    \answ{We have fixed this.}
    
  
\item  Page 38: In the second case of Figure 12 $z$ should be different from $x_1$ and
  $x_2$ and fresh in $Q$. 
  In the third case $s$ should be different from $x$, $u_1$ and $u_2$. 
  In the fourth case $s$ should be different from $x_1$, $x_2$, $u_1$, and $u_2$ and
  fresh in $P$.
  
   \answ{Here again these conditions are correct, but are unnecessary in the light of Barendregt's convention.}
  
  
\item Page 45: Do you not need to explicitly mention some output and input types in
  the Rules Req and Acc and how they are reduced by these rules (similar to the
  Rules Send and Rcv)?
  
  \answ{This is not necessary because Rules Req and Acc cover interaction along shared names which, unlike interactions along linear/session names, are not structured using types. Hence, they have no continuation.}
  
\item  Page 48: Rule Tau introduces stuttering, i.e., allows the type environment to
  perform steps without reducing. Why are you doing that?
  
  \answ{We need this rule because the session environment does not always reduce.
  There is no stuttering because transitions for typed environments come hand-in-hand with
  transitions for processes.}
  
  
\item  Page 51-54: In the first case of the proof of type preservation/soundness you
  start with some arguments about the type derivation for $P$. Since you are in an
  induction, i.e., there might have been parts of terms surrounding $P$, why is it
  safe to assume that the second component of the type environment is empty?
  
  \answ{We work with closed processes (no free variables) for which the second component of the judgment 
  (environment $\Lambda$) is empty. We have clarified this when introducing typed transitions.}
  
   I have difficulties to reconstruct the step from the fourth to the third line.
  I suppose you are applying Rule Rcv here, but that Rule alone does not seem to
  explain the step. Do you maybe have omitted a step here and applied Rcv and
  EProm?
  
  \answ{Yes, we are using Rule Rcv here. There was a typo on the rule as presented in Appendix A; most likely the confusion in reconstructing the derivation originated in that (slightly) incorrect formulation of Rcv.}
  
   I have also difficulties to reconstruct the derivation at the end of Case 1. I
  suppose you are applying Rule Req here, and intuitively the step looks like
  what I would have expected, but Rule Req does not allow the type of $k$ to
  change from the preconditions to the conclusion and Rule Send would require to
  show that the type of $a$ is $\langle S_1\rangle$ and not $S_1$. What am I missing?
  
  \answ{Here we are applying Rule Send; there was a typo on the type of $a$, which we have now corrected.}
  
    In (C.2), (C.4) and the derivation below (C.4) the $X$ should be $x$, right?
  
  \answ{Yes, we have fixed this.}
  
    Twice in (C.2) and once in (C.4) the last type environment $(\Delta)$ starts
  with a $\cdot$.
  
  \answ{We have fixed this.}
  
    In the topmost line of (C.3) there is a $\cdot$ missing before $x$.
  
   \answ{We have fixed this.}
   
    How do you derive the bottom most step in the type derivation below (C.4)?
  Rule Acc does not allow to change the type of $k$ in this step and Rule Rcv does
  not allow for the second part of the type environments to be empty if this is
  not the case above the line.
  
  \answ{Here again we use Rule Rcv, which has been now corrected, as mentioned above.}
  
  Why do you not use the brackets for the encoding functions in Case 3, but do
  so in the other cases?
  
  \answ{We have fixed this.}
  
  Why do you use commata (,) instead of $\cdot$ to combine elements of type
  environments in the Cases 3 and 4?
  
  \answ{We have fixed this.}
  
  Is $S^* = \tilde{T}$ in Case 3? If not, how do you derive (C.5)?
  
  \answ{We have clarified what $S^*$ is - please see the revised proof.}
  
  In the derivation below (C.6) $z$ should be $y$ and $\Delta_{\tilde{n}}$ needs to be
  empty in order to match to the proof goal of this case.
  
  \answ{We have corrected the $y$ and the proof goal ($\Delta$ appears in the typing of the recursive variable).}
  
  In Case 4 do you assume that $\Delta = \Delta_{\tilde{n}}$?
  
  \answ{Yes, we have removed this confusing notation.}
  
  What is the $||ofn(P)||$ in Case 4?

  \answ{We have removed this confusing notation.}
  
  I did not check the other proofs of type preservation/soundness but expect
  similar questions.
  
  \answ{We have checked again the other proofs.}
  
\item Page 56: Should Subcase 2(c) be Subcase 2(b)? 

\answ{Yes, we have fixed this.}

When you derive the steps of the
  encoding of $P$ the equality (between the second and the third line) is actually
  a $\beta$ reduction. 
  
  \answ{Yes, we have fixed this.}
  
  However, Proposition 5.2-2.b)(ii) claims that there is
  first a $\tau_s$ step and then two $\tau_\beta$ steps and not $\tau_\beta$, $\tau_s$,
  $\tau_\beta$. How does this fit together?
  
  \answ{Yes, we have fixed the statement and proof.}
  
\end{enumerate}

\end{document}